<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>深入理解LSTM</title>
    <url>/archives/33247.html</url>
    <content><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>LSTM 是 Long Short Term Memory Networks 的缩写，按字面翻译就是长的短时记忆网络。LSTM 的网络结构是 1997 年由 Hochreiter 和 Schmidhuber 提出的，随后这种网络结构变得非常流行。 LSTM虽然只解决了短期依赖的问题，并且它通过刻意的设计来避免长期依赖问题，这样的做法在实际应用中被证明还是十分有效的，有很多人跟进相关的工作解决了很多实际的问题，所以现在LSTM 仍然被广泛地使用。</p>
<a id="more"></a>

<p>标准的循环神经网络内部只有一个简单的层结构，而 LSTM 内部有 4 个层结构：</p>
<p>第一层是个忘记层：决定状态中丢弃什么信息</p>
<p>第二层tanh层用来产生更新值的候选项，说明状态在某些维度上需要加强，在某些维度上需要减弱</p>
<p>第三层sigmoid层（输入门层），它的输出值要乘到tanh层的输出上，起到一个缩放的作用，极端情况下sigmoid输出0说明相应维度上的状态不需要更新</p>
<p>最后一层决定输出什么，输出值跟状态有关。候选项中的哪些部分最终会被输出由一个sigmoid层来决定。</p>
<p>pytorch 中使用 nn.LSTM 类来搭建基于序列的循环神经网络，他的参数基本与RNN类似。</p>
]]></content>
      <categories>
        <category>循环神经网络</category>
      </categories>
      <tags>
        <tag>自然语言处理</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>PyTorch常用函数汇总</title>
    <url>/archives/45468.html</url>
    <content><![CDATA[<h1 id="nn-Linear"><a href="#nn-Linear" class="headerlink" title="nn.Linear"></a>nn.Linear</h1><a id="more"></a>
<p><img src="../../../images/PyTorch常用函数汇总/image-20201023214312121.png" alt="image-20201023214312121" style="zoom:80%;" /></p>
<p>U指的是均匀分布，即weight权重（A的转置）是取自输入尺寸的倒数再开方后的正负值之间的均匀分布，同理可得偏置bias是输出尺寸的倒数再开方后的正负值之间的均匀分布。</p>
<p>需要实现的内容：</p>
<script type="math/tex; mode=display">
y=x A^{T}+b</script><p>返回的是：</p>
<script type="math/tex; mode=display">
\text { input }^{*} \text { weight }+\text { bias }</script><p><strong>1.初始化</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Linear</span>(<span class="params">Module</span>):</span></span><br><span class="line">	...</span><br><span class="line">	__constants__ = [<span class="string">&#x27;bias&#x27;</span>]</span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_features, out_features, bias=<span class="literal">True</span></span>):</span></span><br><span class="line">	    <span class="built_in">super</span>(Linear, self).__init__()</span><br><span class="line">	    self.in_features = in_features</span><br><span class="line">	    self.out_features = out_features</span><br><span class="line">	    self.weight = Parameter(torch.Tensor(out_features, in_features))</span><br><span class="line">	    <span class="keyword">if</span> bias:</span><br><span class="line">	        self.bias = Parameter(torch.Tensor(out_features))</span><br><span class="line">	    <span class="keyword">else</span>:</span><br><span class="line">	        self.register_parameter(<span class="string">&#x27;bias&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line">	    self.reset_parameters()</span><br></pre></td></tr></table></figure>
<p><strong>2.计算</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@weak_script_method</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, <span class="built_in">input</span></span>):</span></span><br><span class="line">        <span class="keyword">return</span> F.linear(<span class="built_in">input</span>, self.weight, self.bias)</span><br></pre></td></tr></table></figure>
<p><strong>3.举例</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">nn1 = torch.nn.Linear(<span class="number">100</span>, <span class="number">50</span>)</span><br><span class="line">input1 = torch.randn(<span class="number">140</span>, <span class="number">100</span>)</span><br><span class="line">output1 = nn1(input1)</span><br><span class="line">output1.size()</span><br><span class="line">torch.Size([<span class="number">140</span>, <span class="number">50</span>])</span><br></pre></td></tr></table></figure>
<p>张量的大小由 <strong>140 x 100</strong> 变成了 <strong>140 x 50</strong></p>
<p>执行的操作是：</p>
<script type="math/tex; mode=display">
[140,100] \times[100,50]=[140,50]</script><p>to be continue …</p>
<p><br></p>
<p><br></p>
<p><br></p>
<p><img src="../../../images/地波雷达与自动识别系统（AIS）目标点迹最优关联算法/HDU_LOGO.png" alt="HDU_LOGO" style="zoom:50%;" /></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>BP神经网络</title>
    <url>/archives/1231.html</url>
    <content><![CDATA[<h1 id="BP神经网络简介"><a href="#BP神经网络简介" class="headerlink" title="BP神经网络简介"></a>BP神经网络简介</h1><h2 id="网络结构："><a href="#网络结构：" class="headerlink" title="网络结构："></a>网络结构：</h2><p>输入层、隐藏层（实际应用中可能不止一层）和输出层。</p>
<p><img src="../../../images/BP神经网络/image-20201021195702755.png" alt="image-20201021195702755"></p>
<center>BP神经网络架构图</center>

<a id="more"></a>
<p>BP 神经网络里每层的神经元和下一层的神经元用线连接在一起，每条连接线都有一个对应的权重值 w。除了输入层，一般来说每个神经元还有对应的偏置b。BP 神经网络的计算架构如下图 ：</p>
<p><img src="../../../images/BP神经网络/image-20201021195818858.png" alt="image-20201021195818858"></p>
<center>BP 神经网络计算架构图</center>

<p>每个神经元（除了输入层）都会有加权求和得到的输入值  z  ，以及将  z  通过  Sigmoid  函数（也即是激活函数）非线性转化后的输出值  a，z 和 a 的计算公式如下：</p>
<script type="math/tex; mode=display">
z_{j}^{l}=\sum_{i=1 \ldots n} w_{i j} \cdot a_{i j}^{l-1}-b_{j}^{l}</script><script type="math/tex; mode=display">
a_{j}^{l}=f\left(z_{j}^{(l)}\right)=\frac{1}{1+e^{-z_{j}^{(l)}}}</script><p>其中，变量 l 表示层和变量 j 表示的是第  j  个神经元，ij  则表示从编号为  i  的神经元到编号为  j  的神经元之间的连线——边，w  表示的是权重，b  表示的是偏置。BP 神经网络中使用激活函数的原因是因为线性模型（无法处理线性不可分的情况）的表达能力不够，故一般加入  Sigmoid  函数，来实现非线性转换得到神经元的输出值。</p>
<p>Sigmoid 函数图像如下：</p>
<p><img src="../../../images/BP神经网络/image-20201021200606043.png" alt="image-20201021200606043"></p>
<center>sigmoid 函数图像 </center>

<p>Sigmoid 函数的值域为(0,1)。对于多分类任务，输出层的每个神经元可以表示是该分类的概率。当然还存在其他的激活函数如双曲正切函数 tanh 和广泛使用的 Relu 函数，他们的用途和优缺点也都各异。</p>
<h1 id="BP-神经网络算法"><a href="#BP-神经网络算法" class="headerlink" title="BP 神经网络算法"></a>BP 神经网络算法</h1><p>BP 神经网络是一种监督学习，训练预测模型时首先要利用梯度下降法逐层训练和更新网络的权值及阈值，通过训练使网络具备联想记忆和预测能力。 </p>
<p>BP 网络的训练过程如下：<br>1）输入样本以开始信号的正向传播，信号从输入层依次从前往后传递，经过隐藏层，最后传入输出层。<br>2）判断是否将要转向反向传播阶段，具体为：输出层的观测值𝑦̌ =h(x)与期望的输出(y)不符，就进入反向传播阶段。<br>3）误差反传：误差反向传播，利用梯度下降算法，不断修正各层单元的权值和阈值(w 或者 Θ)。<br>4）最终结果：网络输出的误差减少到了另人满意的程度（或者已达到最大训练次数） </p>
<p>在开始介绍 BP 神经网络的标准训练算法前，首先定义 BP 网络结构训练推导会用到的相关变量：我们假设输入层 X 包含 n 个神经元，隐含层 H 包含 p 个神经元，输出层 Y 包含 q 个神经元。 </p>
<p>相关变量的定义见下表：</p>
<p><img src="../../../images/BP神经网络/image-20201021200950428.png" alt="image-20201021200950428"></p>
<p>由于在 BP 网络中，我们输入了 k 个样本分别是$x^{1}, x^{2}, \ldots, x^{\mathrm{k}}$。每个样本输入网络后，会得到观测值，例如第 k 个样本的观测值记为$yo_{o}(k)$，我们将观测值和期望值$d_o(k)$的差值的平方即定义为误差函数𝑒，如式：</p>
<script type="math/tex; mode=display">
e=\frac{1}{2} \sum_{o=1}^{q}\left(d_{o}(k)-y o_{o}(k)\right)^{2}</script><p>基于上面对各变量和对误差函数的定义，BP 神经网络训练的标准推导过程如下。 </p>
<p>第一步，初始化 BP 网络里的各个权值参数，具体来说就是给众权值初始分配一个(-1,1)内的随机数，并且利用设定的误差函数 e，给定计算精度值 ε 和最大学习次数 M。</p>
<p>第二步，要输入的待训练样本 k 如下式：</p>
<script type="math/tex; mode=display">
\mathrm{x}(k)=\left(x_{1}(k), x_{2}(k), \ldots, x_{q}(k)\right)</script><p>以及对应的期望输出如式：</p>
<script type="math/tex; mode=display">
\mathrm{d}_{\mathrm{o}}(k)=\left(d_{1}(k), d_{2}(k), \ldots, d_{q}(k)\right)</script><p>第三步，将样本输入，开始信号正向传播过程，计算各神经元的输入和输出:首先是隐藏层的输入和输出，分别为式：</p>
<script type="math/tex; mode=display">
h i_{h}(k)=\sum_{i=1}^{n} w_{i h} x_{i}(k)-b_{h}, h=1,2, \ldots, p</script><script type="math/tex; mode=display">
h o_{h}(k)=f\left(h i_{h}(k)\right), h=1,2, \ldots p</script><p>第四步，利用网络期望输出和实际输出，开始反向传播阶段，用来修正各神经元权值和阈值，计算误差函数对输出层的各神经元的偏导数$\delta_{o}(k)$，依据链式法则如下式：</p>
<script type="math/tex; mode=display">
\frac{\partial O e}{\partial w_{h o}}=\frac{\partial e}{\partial y i_{o}} \frac{\partial y i_{o}}{\partial w_{h o}}</script><script type="math/tex; mode=display">
\frac{\partial y i_{o}(k)}{\partial w_{h o}}=\frac{\partial\left(\sum_{h}^{p} w_{h o} h o_{h}(k)-b_{o}\right)^{\wedge} 2}{\partial w_{h o}}=h o_{h}(k)</script><script type="math/tex; mode=display">
\begin{aligned}
\frac{\partial e}{\partial y i_{o}} &=\frac{\partial\left(\frac{1}{2} \sum_{o=1}^{q}\left(d_{o}(k)-y o_{o}(k)\right)\right)^{2}}{\partial y i_{o}}=-\left(d_{o}(k)-y o_{o}(k)\right) y o_{o}^{\prime}(k)=-\delta_{o}(k)
\end{aligned}</script><p>第五步，误差继续反向传播至隐藏层，计算误差函数对隐含层各神经元的偏导数$\delta_{h}(k)$依然按照链式法则，可以列出如下等式：</p>
<script type="math/tex; mode=display">
\frac{\partial e}{\partial w_{h o}}=\frac{\partial e}{\partial y i_{o}} \frac{\partial y i_{o}}{\partial w_{h o}}=-\delta_{o}(k) h o_{h}(k)</script><script type="math/tex; mode=display">
\frac{\partial e}{\partial w_{i h}}=\frac{\partial e}{\partial h i_{h}(k)} \frac{\partial h i_{h}(k)}{\partial w_{i h}}</script><script type="math/tex; mode=display">
\frac{\partial h i_{h}(k)}{\partial w_{i h}}=\frac{\partial\left(\sum_{i=1}^{n} w_{i h} x_{i}(k)-b_{h}\right)}{\partial w_{i h}}=x_{i}(k)</script><script type="math/tex; mode=display">
\frac{\partial e}{\partial h i_{h}(k)}=\frac{\partial\left(\frac{1}{2} \sum_{o=1}^{q}\left(d_{o}(k)-y o_{o}(k)\right)\right)^{2}}{\partial h o_{h}(k)} \frac{\partial h o_{h}(k)}{\partial h i_{h}(k)}=-\delta_{h}(k)</script><p>第六步：修正隐藏层和输出层连接权值，步骤如下：</p>
<script type="math/tex; mode=display">
\Delta w_{h o}(k)=-\mu \frac{\partial e}{\partial w_{h o}}=\mu \delta_{o}(k) h o_{h}(k)</script><script type="math/tex; mode=display">
\mathrm{w}_{\mathrm{ho}}^{N+1}=w_{h o}^{N}+\eta \delta_{o}(k) h o_{h}(k)</script><p>第七步，修正输入层和隐藏层连接权值，步骤如下：</p>
<script type="math/tex; mode=display">
\Delta w_{i h}(k)=-\mu \frac{\partial e}{\partial w_{i h}}=\mu \delta_{h}(k) x_{i}(k)</script><script type="math/tex; mode=display">
w_{i h}^{N+1}=w_{i h}^{N}+\eta \delta_{h}(k) x_{i}(k)</script><p>第八步，计算当前的总体误差，表达式如下：</p>
<script type="math/tex; mode=display">
\mathrm{E}=\frac{1}{2 m} \sum_{k=0}^{m} \sum_{o=1}^{q}\left(d_{o}(k)-y o_{o}(k)\right)^{2}</script><p>第九步，判断当前的总体误差是否减少到预设值。如果达到要求或学习次数用尽，则结束训练算法。否则返回到第二步，进入新一轮学习。</p>
<h1 id="BP神经网络改进方法"><a href="#BP神经网络改进方法" class="headerlink" title="BP神经网络改进方法"></a>BP神经网络改进方法</h1><h2 id="提升训练效率"><a href="#提升训练效率" class="headerlink" title="提升训练效率"></a>提升训练效率</h2><p>BP 算法用梯度下降法求误差函数最小值，那么如果误差函数非正定，就一定会存在局部极小点，所以训练的结果不一定落入全局最小点，而是频繁落入极小点，这其实影响了训练效率。事实上，改进 BP 算法就要在一定程度上改善这个问题。一味增大学习率和修正率，会导致函数无法收敛，在极小点震荡。而过于保守选择小步学习率和修正率，则会导致收敛效率太低。显然这两种做法在船舶轨迹动态的预测应用中都是不可取的。所以在这个问题上，需要选取一定的策略调整学习率和权值修正率，前期 BP 网络的误差较大，就选取较大的学习率和权值修正率如选取范围在[0.7,0.9]，使网络在一定的概率下这样学习和训练；当误差减少到较为平稳时候，再将学习率和权值修正率调到低水平比如 0.05 或 0.1，最终使误差函数落入极小点。 </p>
<h2 id="钝化网络"><a href="#钝化网络" class="headerlink" title="钝化网络"></a>钝化网络</h2><p>传统的 BP  网络容易出现过拟合而导致泛化较差。泛化能力是指经过学习的网络对未在学习样本中出现的输入量做出正确反映的能力。过拟合指网络学习的结果过于苛刻。传统的  BP  神经网络泛化能力不好，容易出现过拟合，其主要原因是没有钝化 BP 神经网络而降低其灵敏度。而 BP  网络的灵敏度由权值和阈值直接影响。所以可以将网络的输入变化对输出的灵敏度作为惩罚项加入到转换函数中，达到钝化 BP 网络的目的。</p>
<h2 id="BP-网络层数和隐藏层神经元的数目确定"><a href="#BP-网络层数和隐藏层神经元的数目确定" class="headerlink" title="BP 网络层数和隐藏层神经元的数目确定"></a>BP 网络层数和隐藏层神经元的数目确定</h2><p>BP 神经网络最佳配置的原则是奥卡姆剃刀原理，在 BP 网络解决问题的情况下，如果满足要求则不必要多增加网络层数，这样能减少建模和训练的开销，降低其复杂性。已经在理论层面上证明了只有一层隐藏层的 3 层 BP 网络可以实现任意的非线性关系的映射。再增加层数的 BP 网络虽然收敛效率提高，却也更加容易在训练结束时落入局部极小点。并且增多的网络层数和神经元个数会使网络的泛化能力更弱，更容易出现过拟合的情况。故而一般情况优先选择三层的BP神经网络。</p>
<p><br></p>
<p><br></p>
<p><br></p>
<p><img src="../../../images/序列模型中的注意力机制/HDU_LOGO.png" alt="HDU_LOGO" style="zoom:50%;" /></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>基于AIS的船舶轨迹分析的研究与应用</title>
    <url>/archives/15340.html</url>
    <content><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p><strong>创新点：</strong></p>
<ul>
<li><p>深入探讨了基于 BP 神经网络的船舶轨迹预测模型，通过 AIS 数据提供的信息，针对船舶轨迹预测问题，结合遗传算法，改进了 BP 神经网络轨迹预测模型，并且对不同参数对该模型预测精确度和效率的影响做了研究。</p>
</li>
<li><p>将船舶特有的轨迹特征与时间序列相结合，提出基于深度学习的RNN-LSTM 模型，分析参数并与 GA-BP 神经网络对比，分析出在海上智能交通轨迹预测的方面，基于时间序列的 LSTM 模型的预测能力更强。</p>
</li>
<li><p>利用训练好的模型，提出船舶轨迹预测模型在海上智能交通的应用方面，对目标海域的船舶监控以及异常检测，航路规划等方面。 </p>
<a id="more"></a>


</li>
</ul>
<h1 id="结合遗传算法的-GA-BP-神经网络"><a href="#结合遗传算法的-GA-BP-神经网络" class="headerlink" title="结合遗传算法的 GA-BP 神经网络"></a>结合遗传算法的 GA-BP 神经网络</h1><p>遗传算法具有自适应性，全局优化性和隐含并行性，体现出很强的全局搜索能力。然而遗传算法也有自己的缺陷，遗传算法只能搜索到最优解附近，无法搜索到准确的最优解。也就是说，基本上定位到的是“次优解”，以次优解为起点，继而利用 BP 神经网络梯度下降训练算法继续优化权值参数便可以得到遗传算法找不到的最优解位置。两个算法互补，在一定程度上，克服了 BP 神经网络模型经常落入局部最小点的问题。</p>
<p><img src="../../../images/%E5%9F%BA%E4%BA%8EAIS%E7%9A%84%E8%88%B9%E8%88%B6%E8%BD%A8%E8%BF%B9%E5%88%86%E6%9E%90%E7%9A%84%E7%A0%94%E7%A9%B6%E4%B8%8E%E5%BA%94%E7%94%A8/image-20201021203938328.png" alt="image-20201021203938328"></p>
<center>遗传算法优化 BP神经网络算法流程图</center>

<p>结合两种算法的 GA-BP 神经网络的计算步骤如下：<br>1）选取一种编码方案对 BP 网络的连接权值（神经元阈值）进行编码，产生的分布对应着编码前的权值和阈值。<br>2）输入训练样本，计算它的误差函数值，选择把预测输出和期望输出之间的绝对误差之和作为适应度值；若误差越小，适应度越大，则当前的连接权值作为染色体则更优，反之适应度就小，当前的连接权值作为染色体则更差一些。<br>3）选择操作，将适应度大的个体遗传给下一代 。<br>4）对当前群体进化（变异，交叉），产生下一代的群体。<br>5）重复上述步骤 2 到 4，BP 网络里的参数（权值和阈值）得到不断进化，直到进化代数达到要求或者达到满意的效果为止  。<br>6）步骤 5 完成后，遗传算法得到一组关于 BP 网络参数（权值和阈值）的次优解，再利用 BP 算法进行网络训练得到最优的权值（阈值）。</p>
<h1 id="基于-RNN-LSTM-的船舶轨迹预测模型"><a href="#基于-RNN-LSTM-的船舶轨迹预测模型" class="headerlink" title="基于 RNN-LSTM 的船舶轨迹预测模型"></a>基于 RNN-LSTM 的船舶轨迹预测模型</h1>]]></content>
      <categories>
        <category>舟山海洋项目</category>
      </categories>
      <tags>
        <tag>BP神经网络</tag>
        <tag>遗传算法</tag>
        <tag>LSTM</tag>
      </tags>
  </entry>
  <entry>
    <title>序列模型中的注意力机制</title>
    <url>/archives/28087.html</url>
    <content><![CDATA[<p>现在很多研究的NLP（自然语言处理）问题都可以转换成一个Sequence to Sequence模型来解决，比如说机器翻译，智能问答，语音识别等。</p>
<p>Sequence to Sequence是一个Encoder–Decoder 结构的网络，由一个encoder和一个decoder组成，encoder完成编码工作，将不同的输入编码成一个定长的向量，decoder则完成解码工作，对编码器的结果进行解码输出，例如在中英文翻译中，首先编码器将中文编码成一个向量表示，接着解码器把该向量解码成一个英文表示 ，完成翻译过程。</p>
<a id="more"></a>

<p>但是序列模型会有两个问题，不管输入有多长，它都会把它编码成一个固定长度的向量，若句子比较长，则编码结果会可能会损失较多信息，这将不利于接下来的解码工作；其次在解码的时候，每个时刻的输出在解码过程中用到的上下文向量是相同的，没有做区分，这也会给解码带来问题。为了解决这样的问题，会给模型加入注意力机制（attention mechanism）。</p>
<h1 id="RNN-Encoder-Decoder"><a href="#RNN-Encoder-Decoder" class="headerlink" title="RNN Encoder-Decoder"></a><strong>RNN Encoder-Decoder</strong></h1><p><img src="../../../images/%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/20160120181545780.jpg" alt="20160120181545780"></p>
<center>图2 抽象的文本处理领域的Encoder-Decoder框架</center>

<p>对于句子对&lt;Source,Target&gt;，我们的目标是给定输入句子Source，期待通过Encoder-Decoder框架来生成目标句子Target。Source和Target可以是同一种语言，也可以是两种不同的语言。而Source和Target分别由各自的单词序列构成：<br>$$<br>Source=&lt; x_1,x_2,…,x_m&gt;<br>$$</p>
<p>$$<br>Target=&lt;y_1,y_2,…,y_n&gt;<br>$$</p>
<p>Encoder顾名思义就是对输入句子Source进行编码，将输入句子通过非线性变换转化为中间语义表示C：<br>$$<br>C=f(x_1,x_2,…,x_m)<br>$$<br>对于解码器Decoder来说，其任务是根据句子Source的中间语义表示C和之前已经生成的历史信息$y_1,y_2,…,y_{i-1}$来生成i时刻要生成的单词$y_i$：<br>$$<br>y_i=g(C,y_1,y_2,…,y_{i-1})<br>$$<br>每个$y_i$都依次这么产生，那么看起来就是整个系统根据输入句子Source生成了目标句子Target。如果Source是中文句子，Target是英文句子，那么这就是解决机器翻译问题的Encoder-Decoder框架；如果Source是一篇文章，Target是概括性的几句描述语句，那么这是文本摘要的Encoder-Decoder框架；如果Source是一句问句，Target是一句回答，那么这是问答系统或者对话机器人的Encoder-Decoder框架。由此可见，在文本处理领域，Encoder-Decoder的应用领域相当广泛。</p>
<p>Encoder-Decoder框架不仅仅在文本领域广泛使用，在语音识别、图像处理等领域也经常使用。比如对于语音识别来说，上图所示的框架完全适用，区别无非是Encoder部分的输入是语音流，输出是对应的文本信息；而对于“图像描述”任务来说，Encoder部分的输入是一副图片，Decoder的输出是能够描述图片语义内容的一句描述语。一般而言，文本处理和语音识别的Encoder部分通常采用RNN模型，图像处理的Encoder一般采用CNN模型。</p>
<h1 id="Soft-Attention模型"><a href="#Soft-Attention模型" class="headerlink" title="Soft Attention模型"></a>Soft Attention模型</h1><p>图2中展示的Encoder-Decoder框架是没有体现出“注意力模型”的，所以可以把它看作是注意力不集中的分心模型。为什么说它注意力不集中呢？请观察下目标句子Target中每个单词的生成过程如下：<br>$$<br>\mathrm{y}_{1}=\mathrm{f}(\mathrm{C})<br>$$</p>
<p>$$<br>\mathrm{y}_{2}=\mathrm{f}(\mathrm{C,y_1})<br>$$</p>
<p>$$<br>\mathrm{y}_{3}=\mathrm{f}(\mathrm{C,y_1,y_2})<br>$$</p>
<p>其中f是Decoder的非线性变换函数。从这里可以看出，在生成目标句子的单词时，不论生成哪个单词，它们使用的输入句子Source的语义编码C都是一样的，没有任何区别。</p>
<p>而语义编码C是由句子Source的每个单词经过Encoder 编码产生的，这意味着不论是生成哪个单词，$y_1,y_2$还是$y_3$，其实句子Source中任意单词对生成某个目标单词yi来说影响力都是相同的，这是为何说这个模型没有体现出注意力的缘由。这类似于人类看到眼前的画面，但是眼中却没有注意焦点一样。</p>
<p>如果拿机器翻译来解释这个分心模型的Encoder-Decoder框架更好理解，比如输入的是英文句子：Tom chase Jerry，Encoder-Decoder框架逐步生成中文单词：“汤姆”，“追逐”，“杰瑞”。</p>
<p>在翻译“杰瑞”这个中文单词的时候，分心模型里面的每个英文单词对于翻译目标单词“杰瑞”贡献是相同的，很明显这里不太合理，显然“Jerry”对于翻译成“杰瑞”更重要，但是分心模型是无法体现这一点的，这就是为何说它没有引入注意力的原因。</p>
<p>没有引入注意力的模型在输入句子比较短的时候问题不大，但是如果输入句子比较长，此时所有语义完全通过一个中间语义向量来表示，单词自身的信息已经消失，可想而知会丢失很多细节信息，这也是为何要引入注意力模型的重要原因。</p>
<p>上面的例子中，如果引入Attention模型的话，应该在翻译“杰瑞”的时候，体现出英文单词对于翻译当前中文单词不同的影响程度，比如给出类似下面一个概率分布值：</p>
<p>（Tom,0.3）(Chase,0.2) (Jerry,0.5)</p>
<p>每个英文单词的概率代表了翻译当前单词“杰瑞”时，注意力分配模型分配给不同英文单词的注意力大小。这对于正确翻译目标语单词肯定是有帮助的，因为引入了新的信息。</p>
<p>同理，目标句子中的每个单词都应该学会其对应的源语句子中单词的注意力分配概率信息。这意味着在生成每个单词<img src="https://img-blog.csdnimg.cn/2018122514334020" alt="img">的时候，原先都是相同的中间语义表示C会被替换成根据当前生成单词而不断变化的<img src="https://img-blog.csdnimg.cn/20181225143340243" alt="img">。理解Attention模型的关键就是这里，即由固定的中间语义表示C换成了根据当前输出单词来调整成加入注意力模型的变化的<img src="https://img-blog.csdnimg.cn/20181225143340243" alt="img">。增加了注意力模型的Encoder-Decoder框架理解起来如图3所示。</p>
<img src="../../../images/序列模型中的注意力机制/321412342315.png" alt="321412342315" style="zoom: 80%;" />

<center>图3 引入注意力模型的Encoder-Decoder框架</center>

<p>即生成目标句子单词的过程成了下面的形式：<br>$$<br>y_1=f_1(C_1)<br>$$</p>
<p>$$<br>y_2=f_1(C_2,y_1)<br>$$</p>
<p>$$<br>y_3=f_1(C_3,y_1,y_2)<br>$$</p>
<p>而每个$C_i$可能对应着不同的源语句子单词的注意力分配概率分布，比如对于上面的英汉翻译来说，其对应的信息可能如下：<br>$$<br>\mathrm{C}_{\text {汤姆}}=\mathrm{g}(0.6 * \mathrm{f} 2(\text { “Tom” }), 0.2 * \mathrm{f} 2(\text { Chase }), 0.2 * \mathrm{f} 2(\text { “Jerry” }))<br>$$</p>
<p>$$<br>\mathrm{C}_{\text {追逐 }}=\mathrm{g}(0.2 * \mathrm{f} 2(\text { “Tom” }), 0.7 * \mathrm{f} 2(\text { Chase }), 0.1 * \mathrm{f} 2(\text { “Jerry” }))<br>$$</p>
<p>$$<br>\mathrm{C}_{\text {杰瑞 }}=\mathrm{g}(0.3 * \mathrm{f} 2(\text { “Tom” }), 0.2 * \mathrm{f} 2(\text { Chase }), 0.5 * \mathrm{f} 2(\text { “Jerry” }))<br>$$</p>
<p>其中，f2函数代表Encoder对输入英文单词的某种变换函数，比如如果Encoder是用的RNN模型的话，这个f2函数的结果往往是某个时刻输入$x_i$后隐层节点的状态值；g代表Encoder根据单词的中间表示合成整个句子中间语义表示的变换函数，一般的做法中，g函数就是对构成元素加权求和，即下列公式：<br>$$<br>C_{i}=\sum_{j=1}^{L_{x}} a_{i j} h_{j}<br>$$<br>其中，$L_x$代表输入句子Source的长度，$a_ij$代表在Target输出第i个单词时Source输入句子中第j个单词的注意力分配系数，而$h_j$则是Source输入句子中第j个单词的语义编码。假设$c_i$下标i就是上面例子所说的“ 汤姆” ，那么$L_x$就是3，h1=f(“Tom”)，h2=f(“Chase”),h3=f(“Jerry”)分别是输入句子每个单词的语义编码，对应的注意力模型权值则分别是0.6,0.2,0.2，所以g函数本质上就是个加权求和函数。如果形象表示的话，翻译中文单词“汤姆”的时候，数学公式对应的中间语义表示$C_i$的形成过程类似下图：</p>
<p><img src="../../../images/%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/231455512341243214.png" alt="231455512341243214"></p>
<center> 图4 Attention的形成过程</center>

<p>这里还有一个问题：生成目标句子某个单词，比如“汤姆”的时候，如何知道Attention模型所需要的输入句子单词注意力分配概率分布值呢？就是说“汤姆”对应的输入句子Source中各个单词的概率分布：(Tom,0.6)(Chase,0.2) (Jerry,0.2) 是如何得到的呢？</p>
<p>为了便于说明，我们假设对图2的非Attention模型的Encoder-Decoder框架进行细化，Encoder采用RNN模型，Decoder也采用RNN模型，这是比较常见的一种模型配置，则图2的框架转换为图5：</p>
<p><img src="../../../images/%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/341235413532.png" alt="341235413532"></p>
<center>图5 RNN作为具体模型的Encoder-Decoder框架</center>

<p>那么用图6可以较为便捷地说明注意力分配概率分布值的通用计算过程：</p>
<p><img src="../../../images/%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/231455512341243214.png" alt="231455512341243214"></p>
<center>图6 注意力分配概率计算</center>

<p>对于采用RNN的Decoder来说，在时刻i，如果要生成$y_i$单词，我们是可以知道Target在生成$y_i$之前的时刻i-1时，隐层节点i-1时刻的输出值$H_{i-1}$的，而我们的目的是要计算生成$y_i$时输入句子中的单词“Tom”、“Chase”、“Jerry”对$y_i$来说的注意力分配概率分布，那么可以用Target输出句子i-1时刻的隐层节点状态$H_{i-1}$去一一和输入句子Source中每个单词对应的RNN隐层节点状态$H_j$进行对比，即通过函数$F(h_j,H{i-1})$来获得目标单词$y_i$和每个输入单词对应的对齐可能性，这个F函数在不同论文里可能会采取不同的方法，然后函数F的输出经过Softmax进行归一化就得到了符合概率分布取值区间的注意力分配概率分布数值。</p>
<p>绝大多数Attention模型都是采取上述的计算框架来计算注意力分配概率分布信息，区别只是在F的定义上可能有所不同。图7可视化地展示了在英语-德语翻译系统中加入Attention机制后，Source和Target两个句子每个单词对应的注意力分配概率分布：</p>
<p><img src="../../../images/%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/58678734624563.png" alt="58678734624563"></p>
<center>图7 英语-德语翻译的注意力概率分布</center>

<p>上述内容就是经典的Soft Attention模型的基本思想，那么怎么理解Attention模型的物理含义呢？一般在自然语言处理应用里会把Attention模型看作是输出Target句子中某个单词和输入Source句子每个单词的对齐模型，这是非常有道理的。</p>
<p>目标句子生成的每个单词对应输入句子单词的概率分布可以理解为输入句子单词和这个目标生成单词的对齐概率，这在机器翻译语境下是非常直观的：传统的统计机器翻译一般在做的过程中会专门有一个短语对齐的步骤，而注意力模型其实起的是相同的作用。</p>
<p><img src="../../../images/%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/3246245634.png" alt="3246245634"></p>
<center>图8 Google 神经网络机器翻译系统结构图</center>

<p>图8所示即为Google于2016年部署到线上的基于神经网络的机器翻译系统，相对传统模型翻译效果有大幅提升，翻译错误率降低了60%，其架构就是上文所述的加上Attention机制的Encoder-Decoder框架，主要区别无非是其Encoder和Decoder使用了8层叠加的LSTM模型。</p>
<h1 id="Attention机制的本质思想"><a href="#Attention机制的本质思想" class="headerlink" title="Attention机制的本质思想"></a><strong>Attention机制的本质思想</strong></h1><p>如果把Attention机制从上文讲述例子中的Encoder-Decoder框架中剥离，并进一步做抽象，可以更容易看懂Attention机制的本质思想。</p>
<p><img src="../../../images/%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/2462432634652345.png" alt="2462432634652345"></p>
<center>图9 Attention机制的本质思想</center>

<p>我们可以这样来看待Attention机制（参考图9）：将Source中的构成元素想象成是由一系列的&lt;Key,Value&gt;数据对构成，此时给定Target中的某个元素Query，通过计算Query和各个Key的相似性或者相关性，得到每个Key对应Value的权重系数，然后对Value进行加权求和，即得到了最终的Attention数值。所以本质上Attention机制是对Source中元素的Value值进行加权求和，而Query和Key用来计算对应Value的权重系数。即可以将其本质思想改写为如下公式：<br>$$<br>Attention(Query, Source)=\sum_{i=1}^{L_s}similarity (Query, Key_i)*{ Value }_{i}<br>$$<br>其中，$L_x=||Source||$代表Source的长度，公式含义即如上所述。上文所举的机器翻译的例子里，因为在计算Attention的过程中，Source中的Key和Value合二为一，指向的是同一个东西，也即输入句子中每个单词对应的语义编码，所以可能不容易看出这种能够体现本质思想的结构。</p>
<p>当然，从概念上理解，把Attention仍然理解为从大量信息中有选择地筛选出少量重要信息并聚焦到这些重要信息上，忽略大多不重要的信息，这种思路仍然成立。聚焦的过程体现在权重系数的计算上，权重越大越聚焦于其对应的Value值上，即权重代表了信息的重要性，而Value是其对应的信息。</p>
<p>从图9可以引出另外一种理解，也可以将Attention机制看作一种软寻址（Soft Addressing）:  Source可以看作存储器内存储的内容，元素由地址Key和值Value组成，当前有个Key=Query的查询，目的是取出存储器中对应的Value值，即Attention数值。通过Query和存储器内元素Key的地址进行相似性比较来寻址，之所以说是软寻址，指的不像一般寻址只从存储内容里面找出一条内容，而是可能从每个Key地址都会取出内容，取出内容的重要性根据Query和Key的相似性来决定，之后对Value进行加权求和，这样就可以取出最终的Value值，也即Attention值。所以不少研究人员将Attention机制看作软寻址的一种特例，这也是非常有道理的。</p>
<p> 至于Attention机制的具体计算过程，如果对目前大多数方法进行抽象的话，可以将其归纳为两个过程：第一个过程是根据Query和Key计算权重系数，第二个过程根据权重系数对Value进行加权求和。而第一个过程又可以细分为两个阶段：第一个阶段根据Query和Key计算两者的相似性或者相关性；第二个阶段对第一阶段的原始分值进行归一化处理；这样，可以将Attention的计算过程抽象为如图10展示的三个阶段：</p>
<p><img src="../../../images/%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/432543677.png" alt="432543677"></p>
<center>图10 三阶段计算Attention过程</center>

<p>在第一个阶段，可以引入不同的函数和计算机制，根据Query和某个$Key_i$，计算两者的相似性或者相关性，最常见的方法包括：求两者的向量点积、求两者的向量Cosine相似性或者通过再引入额外的神经网络来求值，即如下方式：<br>$$<br>点积： Similarity( Query, Key_i) = Query · Key_i<br>$$</p>
<p>$$<br>Cosine相似性： Similarity ( Query, Key_i )=\frac{ Query  \cdot K e y_{i}}{| Query|\cdot| Key_i |}<br>$$</p>
<p>$$<br>\text {MLP 网络：} Similarity( Query, Key_i ) = MLP(Query, Key_i)<br>$$</p>
<p>第一阶段产生的分值根据具体产生的方法不同其数值取值范围也不一样，第二阶段引入类似SoftMax的计算方式对第一阶段的得分进行数值转换，一方面可以进行归一化，将原始计算分值整理成所有元素权重之和为1的概率分布；另一方面也可以通过SoftMax的内在机制更加突出重要元素的权重。即一般采用如下公式计算：</p>
<p>$$<br>a_i=Softmax(sim_i)=\frac{e^{sim_i}}{\sum_{j=1}^{L_{x}} e^{sim}_{j}}<br>$$</p>
<p>第二阶段的计算结果$a_i$即为$Value_i$对应的权重系数，然后进行加权求和即可得到Attention数值：</p>
<p>$$<br>\text { Attention(Query, Source) }=\sum_{i=1}^{L_{x}} a_{i} \cdot \text { Value }_{i}<br>$$<br>通过如上三个阶段的计算，即可求出针对Query的Attention数值，目前绝大多数具体的注意力机制计算方法都符合上述的三阶段抽象计算过程。</p>
<h1 id="Self-Attention模型"><a href="#Self-Attention模型" class="headerlink" title="Self Attention模型"></a><strong>Self Attention模型</strong></h1><p>通过上述对Attention本质思想的梳理，我们可以更容易理解本节介绍的Self Attention模型。Self Attention也经常被称为intra Attention（内部Attention），最近一年也获得了比较广泛的使用，比如Google最新的机器翻译模型内部大量采用了Self Attention模型。</p>
<p>在一般任务的Encoder-Decoder框架中，输入Source和输出Target内容是不一样的，比如对于英-中机器翻译来说，Source是英文句子，Target是对应的翻译出的中文句子，Attention机制发生在Target的元素Query和Source中的所有元素之间。而Self Attention顾名思义，指的不是Target和Source之间的Attention机制，而是Source内部元素之间或者Target内部元素之间发生的Attention机制，也可以理解为Target=Source这种特殊情况下的注意力计算机制。其具体计算过程是一样的，只是计算对象发生了变化而已，所以此处不再赘述其计算过程细节。</p>
<p>如果是常规的Target不等于Source情形下的注意力计算，其物理含义正如上文所讲，比如对于机器翻译来说，本质上是目标语单词和源语单词之间的一种单词对齐机制。那么如果是Self Attention机制，一个很自然的问题是：通过Self Attention到底学到了哪些规律或者抽取出了哪些特征呢？或者说引入Self Attention有什么增益或者好处呢？我们仍然以机器翻译中的Self Attention来说明，图11和图12是可视化地表示Self Attention在同一个英语句子内单词间产生的联系。</p>
<p><img src="../../../images/%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/968743.png" alt="968743"></p>
<center>图11 可视化Self Attention实例</center>

<p><img src="../../../images/%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/3333.png" alt="3333"></p>
<center>图12 可视化Self Attention实例</center>

<p>从两张图（图11、图12）可以看出，Self Attention可以捕获同一个句子中单词之间的一些句法特征（比如图11展示的有一定距离的短语结构）或者语义特征（比如图12展示的its的指代对象Law）。</p>
<p>很明显，引入Self Attention后会更容易捕获句子中长距离的相互依赖的特征，因为如果是RNN或者LSTM，需要依次序序列计算，对于远距离的相互依赖的特征，要经过若干时间步步骤的信息累积才能将两者联系起来，而距离越远，有效捕获的可能性越小。</p>
<p>但是Self Attention在计算过程中会直接将句子中任意两个单词的联系通过一个计算步骤直接联系起来，所以远距离依赖特征之间的距离被极大缩短，有利于有效地利用这些特征。除此外，Self Attention对于增加计算的并行性也有直接帮助作用。这是为何Self Attention逐渐被广泛使用的主要原因。</p>
<h1 id="Attention机制的应用"><a href="#Attention机制的应用" class="headerlink" title="Attention机制的应用"></a><strong>Attention机制的应用</strong></h1><p>前文有述，Attention机制在深度学习的各种应用领域都有广泛的使用场景。上文在介绍过程中我们主要以自然语言处理中的机器翻译任务作为例子，下面分别再从图像处理领域和语音识别选择典型应用实例来对其应用做简单说明。</p>
<p><img src="../../../images/%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/23131.png" alt="23131"></p>
<center>图13 描述任务的Encoder-Decoder框架</center>

<p>图片描述（Image-Caption）是一种典型的图文结合的深度学习应用，输入一张图片，人工智能系统输出一句描述句子，语义等价地描述图片所示内容。很明显这种应用场景也可以使用Encoder-Decoder框架来解决任务目标，此时Encoder输入部分是一张图片，一般会用CNN来对图片进行特征抽取，Decoder部分使用RNN或者LSTM来输出自然语言句子（参考图13）。</p>
<p>此时如果加入Attention机制能够明显改善系统输出效果，Attention模型在这里起到了类似人类视觉选择性注意的机制，在输出某个实体单词的时候会将注意力焦点聚焦在图片中相应的区域上。图14给出了根据给定图片生成句子“A person is standing on a beach with a surfboard.”过程时每个单词对应图片中的注意力聚焦区域。</p>
<p><img src="../../../images/%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/24124.png" alt="24124"></p>
<center>图14 图片生成句子中每个单词时的注意力聚焦区域</center>

<p>图15给出了另外四个例子形象地展示了这种过程，每个例子上方左侧是输入的原图，下方句子是人工智能系统自动产生的描述语句，上方右侧图展示了当AI系统产生语句中划横线单词的时候，对应图片中聚焦的位置区域。比如当输出单词dog的时候，AI系统会将注意力更多地分配给图片中小狗对应的位置。</p>
<p><img src="../../../images/%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/34234234.png" alt="34234234"></p>
<center>图15 图像描述任务中Attention机制的聚焦作用</center>

<p><img src="../../../images/%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/242423.png" alt="242423"></p>
<center>图16 语音识别中音频序列和输出字符之间的Attention</center>

<p>语音识别的任务目标是将语音流信号转换成文字，所以也是Encoder-Decoder的典型应用场景。Encoder部分的Source输入是语音流信号，Decoder部分输出语音对应的字符串流。</p>
<p>图16可视化地展示了在Encoder-Decoder框架中加入Attention机制后，当用户用语音说句子 how much would a woodchuck chuck 时，输入部分的声音特征信号和输出字符之间的注意力分配概率分布情况，颜色越深代表分配到的注意力概率越高。从图中可以看出，在这个场景下，Attention机制起到了将输出字符和输入语音信号进行对齐的功能。</p>
<p>上述内容仅仅选取了不同AI领域的几个典型Attention机制应用实例，Encoder-Decoder加Attention架构由于其卓越的实际效果，目前在深度学习领域里得到了广泛的使用，了解并熟练使用这一架构对于解决实际问题会有极大帮助。</p>
<br>

<br>

<br>

<img src="../../../images/序列模型中的注意力机制/HDU_LOGO.png" alt="HDU_LOGO" style="zoom:50%;" />]]></content>
      <categories>
        <category>循环神经网络</category>
      </categories>
      <tags>
        <tag>自然语言处理</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>地波雷达与自动识别系统（AIS）目标点迹最优关联算法</title>
    <url>/archives/2904.html</url>
    <content><![CDATA[<h1 id="问题简介"><a href="#问题简介" class="headerlink" title="问题简介"></a>问题简介</h1><h2 id="进出港非法渔船研判"><a href="#进出港非法渔船研判" class="headerlink" title="进出港非法渔船研判"></a>进出港非法渔船研判</h2><p>研判三要素：</p>
<ol>
<li>船舶进出港登记人员是否在册（查数据库）√</li>
<li>视频设备获取的船舶id是否在册（查数据库）√</li>
<li>雷达扫描到的船舶是否有与之匹配的AIS点位（点迹匹配）？</li>
</ol>
<p>研判港口渔船的合法性有以上三个要素，其中前两个可以通过简单的数据库查询做出判断，但是第三点由于AIS数据和雷达数据间的弱关联性，需要做进一步处理。</p>
<a id="more"></a>
<h1 id="点迹匹配"><a href="#点迹匹配" class="headerlink" title="点迹匹配"></a>点迹匹配</h1><p>一艘合规的船需要有配对的雷达点位和AIS点位，但由于这两个数据的关联性较弱、数据间的发送间隔也不相同，所以两个点位往往有一定的时空误差。</p>
<p><img src="../../../images/地波雷达与自动识别系统（AIS）目标点迹最优关联算法/ais_radar.png" alt="ais_radar"></p>
<ul>
<li>雷达数据（被动）：船舶位置、航速、航向、船舶长度、时间等，雷达数据较真实可靠，速度探测精度高，但位置精度低，无法确定到船的具体信息。</li>
<li>AIS数据（主动）：AIS设备ID（唯一，且与船舶id配对）、船舶位置、航速、航向、温度、时间等，AIS数据能确定到具体某一艘船，但会存在漏报、谎报的情况。</li>
</ul>
<h1 id="研究过程"><a href="#研究过程" class="headerlink" title="研究过程"></a>研究过程</h1><h2 id="主要步骤"><a href="#主要步骤" class="headerlink" title="主要步骤"></a>主要步骤</h2><p>首先，将WGS84(World Geodetic System 1984)坐标系下测量的AIS的点迹和高频地波雷达点迹映射到极坐标中，实现坐标系的统一。<br>其次，建立高频地波雷达和AIS点迹关联模型，采用状态划分和迭代搜索算法将关联数据集划分为可行的关联子集。<br>最后，将JVC全局最优关联算法应用于每一个可行关联子集的点迹关联上，解决密集环境中的雷达和AIS点迹关联问题。</p>
<h3 id="统一坐标系"><a href="#统一坐标系" class="headerlink" title="统一坐标系"></a>统一坐标系</h3><p><img src="../../../images/地波雷达与自动识别系统（AIS）目标点迹最优关联算法/image-20201019100537524.png" alt="image-20201019100537524"></p>
<h3 id="计算径向速度"><a href="#计算径向速度" class="headerlink" title="计算径向速度"></a>计算径向速度</h3><p><img src="../../../images/地波雷达与自动识别系统（AIS）目标点迹最优关联算法/径向速度就算.png" alt="径向速度就算"></p>
<h3 id="分状态划分测试集"><a href="#分状态划分测试集" class="headerlink" title="分状态划分测试集"></a>分状态划分测试集</h3><p><img src="../../../images/地波雷达与自动识别系统（AIS）目标点迹最优关联算法/分状态.png" alt="分状态" style="zoom:80%;" /></p>
<p>根据径向速度、距离等信息，利用门限阈值将雷达和AIS数据划分为静态和动态两类，提高运算速度和匹配精度。</p>
<h3 id="迭代搜索"><a href="#迭代搜索" class="headerlink" title="迭代搜索"></a>迭代搜索</h3><p><img src="../../../images/地波雷达与自动识别系统（AIS）目标点迹最优关联算法/迭代搜索.png" alt="迭代搜索"></p>
<h3 id="JVC最优点迹匹配"><a href="#JVC最优点迹匹配" class="headerlink" title="JVC最优点迹匹配"></a>JVC最优点迹匹配</h3><p><img src="../../../images/地波雷达与自动识别系统（AIS）目标点迹最优关联算法/点迹匹配.png" alt="点迹匹配"></p>
<p>算法输入：代价矩阵（矩阵元是雷达点和AIS点之间的距离）</p>
<p>算法输出：最小总代价，匹配的点迹对</p>
<h1 id="算法复现"><a href="#算法复现" class="headerlink" title="算法复现"></a>算法复现</h1><h2 id="论文实验"><a href="#论文实验" class="headerlink" title="论文实验"></a>论文实验</h2><p>论文数据：<br>2011年10月31日09:18:50时的336个雷达目标点迹（真实数据）和443个AIS点迹（仿真数据）</p>
<p>算法比较：</p>
<p>选用了最近邻算法、Munkres算法、分状态JVC算法进行点迹关联比较，测试结果如下：</p>
<p><img src="../../../images/地波雷达与自动识别系统（AIS）目标点迹最优关联算法/image-20201019102705995.png" alt="image-20201019102705995"></p>
<p><img src="../../../images/地波雷达与自动识别系统（AIS）目标点迹最优关联算法/image-20201019102846557.png" alt="image-20201019102846557"></p>
<p>实验结果表明，该算法在同样关联51对点迹的情况下，关联精度高于最近邻算法和Munkres法，关联用时少于最近邻算法和Munkres法，为地波雷达与AIS目标点迹关联提供了一种可行的方法，但是，由于雷达的目标定位精度较低，雷达与 AIS 的点迹关联比例较低，下一步可以考虑进一步融合高精度的 SAR 图像数据进行船只点迹目标融合探测，以便提高海洋探测的精度和范围，同时可以起到校准雷达精度的作用。</p>
<h2 id="复现实验"><a href="#复现实验" class="headerlink" title="复现实验"></a>复现实验</h2><p>实验数据：舟山海域2020年9月11日20:19:03时-2020年9月11日20:21:03的163个雷达点迹和45个AIS点迹进行点迹关联。</p>
<p><img src="../../../images/地波雷达与自动识别系统（AIS）目标点迹最优关联算法/image-20201019104718012.png" alt="image-20201019104718012" style="zoom:80%;" /></p>
<p><img src="../../../images/地波雷达与自动识别系统（AIS）目标点迹最优关联算法/image-20201019104834241.png" alt="image-20201019104834241" style="zoom:124%;" /></p>
<h1 id="参考论文"><a href="#参考论文" class="headerlink" title="参考论文"></a>参考论文</h1><p>张晖.<em>舰船目标多手段数据融合探测方法研究</em>.2016.内蒙古大学,PhD dissertation.</p>
<p>张晖,刘永信,张杰,纪永刚,郑志强.<em>地波雷达与自动识别系统目标点迹最优关联算法</em>[J].电子与信息学报,2015,37(03):619-624.</p>
<p><br></p>
<p><br></p>
<p><br></p>
<p><img src="../../../images/地波雷达与自动识别系统（AIS）目标点迹最优关联算法/HDU_LOGO.png" alt="HDU_LOGO" style="zoom:50%;" /></p>
]]></content>
      <categories>
        <category>舟山海洋项目</category>
      </categories>
      <tags>
        <tag>数据融合</tag>
      </tags>
  </entry>
  <entry>
    <title>A-robust-Delaunay-AFT-based-parallel-method-for-the-generation-of-large-scale-fully-constrained-meshes</title>
    <url>/archives/28714.html</url>
    <content><![CDATA[<p>Fei Yu,Yan Zeng,Z.Q. Guan,S.H. Lo. A robust Delaunay-AFT based parallel method for the generation of large-scale fully constrained meshes[J]. Computers and Structures,2020,228.</p>
<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>本文研究者充分利用串行Delaunay-AFT网格生成器，<u>开发了一种在分布式存储的机器上生成大规模四面体网格的并行方法</u>。 </p>
<p>为了生成具有所需和保留属性的网格，<u>使用了一种基于Delaunay-AFT的域分解(DD)技术</u>。从覆盖问题域的Delaunay三角剖分(DT)开始，该技术创建了一层元素，将整个域划分为几个区域。将最初粗糙的网格域划分为了可以进行并行网格划分的子域的DTs。 当一个子域的大小小于用户指定的阈值，将用标准Delaunay-AFT方法进行网格划分。     </p>
<p><u>设计了两级DD策略来提高了该算法的并行效率</u>。<u>还使用消息传递接口(MPI)实现了动态负载均衡方案</u>。 <u>引入了核心外网格划分，以适应过大的网格</u>，而这些网格不能由计算机的可用存储器(RAM)处理。 <u>对具有数千个表面贴片的各种复杂几何形状进行了数值试验，创建了拥有超过100亿个四面体元素的超大尺度网格</u>。 此外，不同DD操作次数生成的网格在质量上几乎相同：显示了自动分解算法的一致性和稳定性。</p>
<a id="more"></a>
<h1 id="具体论文"><a href="#具体论文" class="headerlink" title="具体论文"></a>具体论文</h1><h2 id="并行域分解和网格产生算法"><a href="#并行域分解和网格产生算法" class="headerlink" title="并行域分解和网格产生算法"></a>并行域分解和网格产生算法</h2><p><img src="../../../images/A-robust-Delaunay-AFT-based-parallel-method-for-the-generation-of-large-scale-fully-constrained-meshes/image-20201016180107878.png" alt="image-20201016180107878"></p>
<h2 id="并行域分解和网格产生算法-1"><a href="#并行域分解和网格产生算法-1" class="headerlink" title="并行域分解和网格产生算法"></a>并行域分解和网格产生算法</h2><p><img src="../../../images/A-robust-Delaunay-AFT-based-parallel-method-for-the-generation-of-large-scale-fully-constrained-meshes/image-20201016193028229.png" alt="image-20201016193028229"></p>
<h2 id="一级域分解"><a href="#一级域分解" class="headerlink" title="一级域分解"></a>一级域分解</h2><p><img src="../images/A-robust-Delaunay-AFT-based-parallel-method-for-the-generation-of-large-scale-fully-constrained-meshes/image-20201016180334321.png" alt="image-20201016180334321" style="zoom: 80%;" /></p>
<p>（a）进行CDT分解的区域。</p>
<p>（b）扩展的Delaunay-AFT方法引入了一层形状良好的单元作为分离层。</p>
<p>（c）独立的并行处理器进行进一步的域分解。</p>
<p>（d）并行子域网格生成的中间阶段，三个处理器完成，一个正在进行。</p>
<h2 id="二级域分解"><a href="#二级域分解" class="headerlink" title="二级域分解"></a>二级域分解</h2><p><img src="../../../images/A-robust-Delaunay-AFT-based-parallel-method-for-the-generation-of-large-scale-fully-constrained-meshes/image-20201016192227404.png" alt="image-20201016192227404"></p>
<p>(a) 引入L0,L1分割切割面。</p>
<p>(b) 将领域用L0,L1周围的分割元划分成四个不完全的区域。</p>
<p>(c)通过并行的处理器在平面Π周围生成分割面。</p>
<p>(d)不完全的区域合并成了单个区域，然后通过Π周围的分割元自动分为了两个子区域。</p>
<p><img src="../../../images/A-robust-Delaunay-AFT-based-parallel-method-for-the-generation-of-large-scale-fully-constrained-meshes/image-20201016192433173.png" alt="image-20201016192433173"></p>
<p>上图是二级域分解的直观情况，（a）是在切割线周围产生分割元，（b）是在切割面周围产生分割元</p>
<h1 id="动态负载均衡"><a href="#动态负载均衡" class="headerlink" title="动态负载均衡"></a>动态负载均衡</h1><p><img src="../../../images/A-robust-Delaunay-AFT-based-parallel-method-for-the-generation-of-large-scale-fully-constrained-meshes/image-20201016192634936.png" alt="image-20201016192634936"></p>
<p>由于Delaunay-AFT法网格生成的速度与各种因素的组合有关，因此难以准确地评价网格划分工作。</p>
<p>因此，相比于静态负载分配，动态负载均衡策略更合适。</p>
<p>网格域被划分为比处理器数(Np)多得多的子域。 然后将处理器动态地分配进行网格生成。如算法3所示，基本实现结构是主/从模型。在这个模型中，主处理器接收请求，并指示从处理器执行它们，从处理器独立于其他从处理器运行。</p>
<h1 id="核心外网格划分"><a href="#核心外网格划分" class="headerlink" title="核心外网格划分"></a>核心外网格划分</h1><p><img src="../../../images/A-robust-Delaunay-AFT-based-parallel-method-for-the-generation-of-large-scale-fully-constrained-meshes/image-20201016192725596.png" alt="image-20201016192725596"></p>
<p> 由于主从模型有很强的解耦性和简单性，所以核外的网格划分能通过改变消息传递的方式简单地实现。</p>
<p>网格数据被序列化之后使用MPI_Send和MPI_Recv方法在处理器之间传输数据。</p>
<p>但是，当从机需要发送网格数据给主机，然后主机需要广播数据给从机时，通信开销会变得非常大，这也是并行方法的瓶颈。</p>
<p>在本工作中，序列化的网格数据被转储到处理器之间共享的磁盘上，并将表示相应文件路径的字符串视为对需要传递的数据的代替，由于文件路径的字符串长度很小，主机通讯的时间可以忽略不计，所以通讯开销会变得很小。</p>
<p>同时，完成的网格立即导出以释放内存，这样，内存需求明显降低，因为只有正在处理的网格保存在RAM中。 </p>
<h1 id="测试结果"><a href="#测试结果" class="headerlink" title="测试结果"></a>测试结果</h1><h2 id="加速比"><a href="#加速比" class="headerlink" title="加速比"></a>加速比</h2><p>分别对齿轮箱、显卡、喷气引擎进行了网格划分测试。</p>
<p><img src="../../../images/A-robust-Delaunay-AFT-based-parallel-method-for-the-generation-of-large-scale-fully-constrained-meshes/image-20201016192809878.png" alt="image-20201016192809878"></p>
<h2 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h2><p><img src="../../../images/A-robust-Delaunay-AFT-based-parallel-method-for-the-generation-of-large-scale-fully-constrained-meshes/image-20201016193252883.png" alt="image-20201016193252883"></p>
<p><img src="../../../images/A-robust-Delaunay-AFT-based-parallel-method-for-the-generation-of-large-scale-fully-constrained-meshes/image-20201016193258301.png" alt="image-20201016193258301"></p>
<h2 id="网格质量"><a href="#网格质量" class="headerlink" title="网格质量"></a>网格质量</h2><p>网格质量通过以下公式定义：</p>
<script type="math/tex; mode=display">
\sigma=3\frac{r_i}{r_c}</script><p>其中$r_i$是内接圆半径，$r_c$是外接圆半径，$\sigma$越接近1，说明网格的形状越接近正四面体，质量越高，由于实际正四面体的内外接圆半径之比为$\frac{1}{3}$，所以乘上3归一化。</p>
<p><img src="../../../images/A-robust-Delaunay-AFT-based-parallel-method-for-the-generation-of-large-scale-fully-constrained-meshes/image-20201016193551630.png" alt="image-20201016193551630"></p>
<p>上图是三个模型在不同网格质量下的网格数目，可见并行对网格质量影响不大，生成网格大部分都为高质量网格。</p>
<p><br></p>
<p><br></p>
<p><br></p>
<p><img src="../images/A-robust-Delaunay-AFT-based-parallel-method-for-the-generation-of-large-scale-fully-constrained-meshes/HDU_LOGO.png" alt="HDU_LOGO" style="zoom:50%;" /></p>
]]></content>
      <categories>
        <category>并行与分布式计算</category>
      </categories>
      <tags>
        <tag>并行与分布式计算</tag>
        <tag>网格划分</tag>
      </tags>
  </entry>
  <entry>
    <title>基于GPU的矩阵计算并行加速方法研究</title>
    <url>/archives/9502.html</url>
    <content><![CDATA[<p>李丰.<em>基于GPU的矩阵计算并行加速方法研究</em>.2018.哈尔滨工业大学,PhD dissertation.</p>
]]></content>
      <categories>
        <category>并行与分布式计算</category>
      </categories>
      <tags>
        <tag>并行与分布式计算</tag>
      </tags>
  </entry>
  <entry>
    <title>PAC2020:傅里叶空间图像相似度计算</title>
    <url>/archives/62775.html</url>
    <content><![CDATA[<h1 id="赛题描述"><a href="#赛题描述" class="headerlink" title="赛题描述"></a>赛题描述</h1><p>在蛋白质冷冻电镜三维重构程序中，将二维真实图像与空间中的三维结构的投影图像的相似度计算是调用最为频繁的计算，相似度计算的原理是求取真实图像与投影图像的所有像素在傅里叶空间中的二范数之和，公式如下：</p>
<script type="math/tex; mode=display">
diff=\sum_{i=1}^{N}{a*||image_i-proj_i||}</script><p><img src="../../../images/PAC2020-傅里叶空间图像相似度计算/image-20201015095633405.png" alt="image-20201015095633405" style="zoom: 50%;" /></p>
<p>比赛的目的是将赛方提供的相似度计算程序进行并行加速，输出结果精度误差不超过十万分之一，比赛的代码包里提供了校验文件。</p>
<a id="more"></a>
<h1 id="运行环境"><a href="#运行环境" class="headerlink" title="运行环境"></a>运行环境</h1><h2 id="硬件："><a href="#硬件：" class="headerlink" title="硬件："></a>硬件：</h2><p>处理器：Intel Xeon处理器 Platinum 9242 CPU @ 2.30GHz 24*8G </p>
<p>网络：100Gb Intel omnipath</p>
<h2 id="软件："><a href="#软件：" class="headerlink" title="软件："></a>软件：</h2><p>操作系统：CentOS 8.0  </p>
<p>并行环境：Intel MPI</p>
<p>相关依赖软件：VTune Profiler 2020、ParaCloud平台的ssh连接工具等</p>
<p>应用负载：96个逻辑核心</p>
<h1 id="优化后的代码结构"><a href="#优化后的代码结构" class="headerlink" title="优化后的代码结构"></a>优化后的代码结构</h1><p><img src="../../../images/PAC2020-傅里叶空间图像相似度计算/image-20201014211614779.png" alt="image-20201014211614779" style="zoom:80%;" /></p>
<h1 id="优化过程"><a href="#优化过程" class="headerlink" title="优化过程"></a>优化过程</h1><h2 id="MPI进程级并行优化-amp-MPI-IO优化"><a href="#MPI进程级并行优化-amp-MPI-IO优化" class="headerlink" title="MPI进程级并行优化&amp;MPI-IO优化"></a>MPI进程级并行优化&amp;MPI-IO优化</h2><p><img src="../../../images/PAC2020-傅里叶空间图像相似度计算/image-20201014202814651.png" alt="image-20201014202814651"></p>
<p><img src="../../../images/PAC2020-傅里叶空间图像相似度计算/image-20201014202730183.png" alt="image-20201014202730183"></p>
<p>对于源代码计算部分的外层循环，通过进程号将大的循环体划分成数个小循环并行执行，多出的子任务分配给进程号最大的进程。I/O方面的优化点在于，通过预先确定结果文件指针的偏移量，每轮计算结果不再直接输出，而是根据偏移量存入当前进程创建的一片内存空间中的对应位置，各进程在计算任务结束后整体写入结果文件中。</p>
<h3 id="优化结果-amp-性能指标-MPI"><a href="#优化结果-amp-性能指标-MPI" class="headerlink" title="优化结果&amp;性能指标(MPI)"></a>优化结果&amp;性能指标(MPI)</h3><p>  <img src="../../../images/PAC2020-傅里叶空间图像相似度计算/image-20201015082916436.png" alt="image-20201015082916436"></p>
<h2 id="OpenMP线程级并行优化-amp-AVX优化"><a href="#OpenMP线程级并行优化-amp-AVX优化" class="headerlink" title="OpenMP线程级并行优化&amp;AVX优化"></a>OpenMP线程级并行优化&amp;AVX优化</h2><p><img src="../../../images/PAC2020-傅里叶空间图像相似度计算/image-20201014204736870.png" alt="image-20201014204736870" style="zoom:80%;" /></p>
<p>利用OpenMP对计算部分的内层循环进行归约优化，简单实现线程级的并行。</p>
<p>对于实际计算部分，我利用了AVX指令改写了原来计算部分的代码，通过调用AVX的512位向量寄存器，一次可以操作512/32=16个float型浮点数(损失的精度在规则范围内)，而一个float型复数会占用2个float型浮点数长度的地址，所以最终能达到8路并行，即一次操作本来需要八轮循环操作的数据，运算速度有较大提升。</p>
<h3 id="优化结果-amp-性能指标-MPI-OpenMP"><a href="#优化结果-amp-性能指标-MPI-OpenMP" class="headerlink" title="优化结果&amp;性能指标(MPI+OpenMP)"></a>优化结果&amp;性能指标(MPI+OpenMP)</h3><p><img src="../../../images/PAC2020-傅里叶空间图像相似度计算/image-20201015091631843.png" alt="image-20201015091631843"></p>
<h3 id="优化结果-amp-性能指标-MPI-OpenMP-AVX-编译优化"><a href="#优化结果-amp-性能指标-MPI-OpenMP-AVX-编译优化" class="headerlink" title="优化结果&amp;性能指标(MPI+OpenMP+AVX+编译优化)"></a>优化结果&amp;性能指标(MPI+OpenMP+AVX+编译优化)</h3><p><img src="../../../images/PAC2020-傅里叶空间图像相似度计算/image-20201015091754886.png" alt="image-20201015091754886"></p>
<h1 id="Vtune测试结果"><a href="#Vtune测试结果" class="headerlink" title="Vtune测试结果"></a>Vtune测试结果</h1><p>原程序计算时间为两个半小时左右，经优化后，程序计算时间为12秒左右，加速了735倍。</p>
<p><img src="../../../images/PAC2020-傅里叶空间图像相似度计算/image-20201015092113391.png" alt="image-20201015092113391"></p>
<p><br></p>
<p><br></p>
<p><br></p>
<p><img src="../../../images/PAC2020-傅里叶空间图像相似度计算/HDU_LOGO.png" alt="HDU_LOGO" style="zoom:50%;" /></p>
]]></content>
      <categories>
        <category>并行与分布式计算</category>
      </categories>
      <tags>
        <tag>并行与分布式计算</tag>
        <tag>计算机类竞赛</tag>
      </tags>
  </entry>
</search>
